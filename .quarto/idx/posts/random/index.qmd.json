{"title":"Exploring XGBoost: Predictive Modeling and Visualization","markdown":{"yaml":{"title":"Exploring XGBoost: Predictive Modeling and Visualization","author":"Yeswanth Chitirala","date":"2024-01-14","categories":["news","code","analysis"],"image":"image.jpg"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\n\n```{r}\n# Load required libraries\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(caret)\nlibrary(plotly)\nlibrary(xgboost)\n\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Generate a random dataframe\nn <- 100\nrandom_df <- data.frame(\n  X1 = rnorm(n),\n  X2 = rnorm(n),\n  X3 = rnorm(n)\n)\n\n# Add the Y column based on X1, X2, and X3\nrandom_df$Y <- 2 * random_df$X1 - 3 * random_df$X2 + 0.5 * random_df$X3 + rnorm(n)\n\n# Display the first few rows of the dataframe\nprint(\"Random Dataframe:\")\nprint(head(random_df))\n\n```\n\n## MODELLING \n\n```{r}\n# Set seed for reproducibility\nset.seed(123)\n\n# Split the data into training and testing sets\ntrain_indices <- createDataPartition(random_df$Y, p = 0.8, list = FALSE)\ntrain_data <- random_df[train_indices, ]\ntest_data <- random_df[-train_indices, ]\n\n# Create an XGBoost model\nxgb_model <- xgboost(data = as.matrix(train_data[, -4]), label = train_data$Y, nrounds = 100)\n\n# Make predictions on the test set\npredictions <- predict(xgb_model, as.matrix(test_data[, -4]))\n\n# Evaluate model performance\naccuracy <- sqrt(mean((predictions - test_data$Y)^2))\n\n# Display the accuracy\nprint(paste(\"Model RMSE:\", round(accuracy, 4)))\n```\n\n# VISUALIZATION \n\n```{r}\n\n# Visualize actual vs. predicted values using plotly\nplot_data <- data.frame(Actual = test_data$Y, Predicted = predictions)\n\nplot <- plot_ly(plot_data, x = ~Actual, y = ~Predicted, type = 'scatter', mode = 'markers',\n                marker = list(color = 'blue', size = 8),\n                text = paste(\"Actual: \", test_data$Y, \"<br>Predicted: \", round(predictions, 4)))\n\nlayout <- list(title = \"Actual vs. Predicted Values\",\n               xaxis = list(title = \"Actual Values\"),\n               yaxis = list(title = \"Predicted Values\"))\n\nplot <- plot %>% layout(layout)\n\n# Display the interactive plot\nprint(plot)\n```\n\nThe root mean squared error (RMSE) of the XGBoost model is 1.6629. RMSE is a measure of the average deviation between the predicted and actual values, and in this context, a lower RMSE indicates better model performance. In other words, the model, on average, is making predictions that are approximately 1.6629 units away from the true values. While assessing model accuracy, it's crucial to consider the scale and context of the problem at hand. Comparing the RMSE to the range of the target variable can provide insights into the practical significance of the error. In this case, the model's performance appears reasonable, but further analysis and comparison with alternative models or baseline approaches may provide a more comprehensive understanding of its effectiveness.\n","srcMarkdownNoYaml":"\n\n## Introduction\n\n\n```{r}\n# Load required libraries\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(caret)\nlibrary(plotly)\nlibrary(xgboost)\n\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Generate a random dataframe\nn <- 100\nrandom_df <- data.frame(\n  X1 = rnorm(n),\n  X2 = rnorm(n),\n  X3 = rnorm(n)\n)\n\n# Add the Y column based on X1, X2, and X3\nrandom_df$Y <- 2 * random_df$X1 - 3 * random_df$X2 + 0.5 * random_df$X3 + rnorm(n)\n\n# Display the first few rows of the dataframe\nprint(\"Random Dataframe:\")\nprint(head(random_df))\n\n```\n\n## MODELLING \n\n```{r}\n# Set seed for reproducibility\nset.seed(123)\n\n# Split the data into training and testing sets\ntrain_indices <- createDataPartition(random_df$Y, p = 0.8, list = FALSE)\ntrain_data <- random_df[train_indices, ]\ntest_data <- random_df[-train_indices, ]\n\n# Create an XGBoost model\nxgb_model <- xgboost(data = as.matrix(train_data[, -4]), label = train_data$Y, nrounds = 100)\n\n# Make predictions on the test set\npredictions <- predict(xgb_model, as.matrix(test_data[, -4]))\n\n# Evaluate model performance\naccuracy <- sqrt(mean((predictions - test_data$Y)^2))\n\n# Display the accuracy\nprint(paste(\"Model RMSE:\", round(accuracy, 4)))\n```\n\n# VISUALIZATION \n\n```{r}\n\n# Visualize actual vs. predicted values using plotly\nplot_data <- data.frame(Actual = test_data$Y, Predicted = predictions)\n\nplot <- plot_ly(plot_data, x = ~Actual, y = ~Predicted, type = 'scatter', mode = 'markers',\n                marker = list(color = 'blue', size = 8),\n                text = paste(\"Actual: \", test_data$Y, \"<br>Predicted: \", round(predictions, 4)))\n\nlayout <- list(title = \"Actual vs. Predicted Values\",\n               xaxis = list(title = \"Actual Values\"),\n               yaxis = list(title = \"Predicted Values\"))\n\nplot <- plot %>% layout(layout)\n\n# Display the interactive plot\nprint(plot)\n```\n\nThe root mean squared error (RMSE) of the XGBoost model is 1.6629. RMSE is a measure of the average deviation between the predicted and actual values, and in this context, a lower RMSE indicates better model performance. In other words, the model, on average, is making predictions that are approximately 1.6629 units away from the true values. While assessing model accuracy, it's crucial to consider the scale and context of the problem at hand. Comparing the RMSE to the range of the target variable can provide insights into the practical significance of the error. In this case, the model's performance appears reasonable, but further analysis and comparison with alternative models or baseline approaches may provide a more comprehensive understanding of its effectiveness.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.353","editor":"visual","theme":"vapor","title-block-banner":true,"title":"Exploring XGBoost: Predictive Modeling and Visualization","author":"Yeswanth Chitirala","date":"2024-01-14","categories":["news","code","analysis"],"image":"image.jpg"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}
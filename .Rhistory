library(ggplot2)
library(caret)
library(plotly)
library(e1071)
# Set seed for reproducibility
set.seed(123)
# Generate a random dataframe
n <- 100
random_df <- data.frame(
X1 = rnorm(n),
X2 = rnorm(n),
X3 = rnorm(n)
)
# Add the Y column based on X1, X2, and X3
random_df$Y <- 2 * random_df$X1 - 3 * random_df$X2 + 0.5 * random_df$X3 + rnorm(n)
# Display the first few rows of the dataframe
print("Random Dataframe:")
print(head(random_df))
# Load required libraries
library(dplyr)
library(ggplot2)
library(caret)
library(plotly)
library(e1071)
# Set seed for reproducibility
set.seed(123)
# Generate a random dataframe
n <- 100
random_df <- data.frame(
X1 = rnorm(n),
X2 = rnorm(n),
X3 = rnorm(n)
)
# Add the Y column based on X1, X2, and X3
random_df$Y <- 2 * random_df$X1 - 3 * random_df$X2 + 0.5 * random_df$X3 + rnorm(n)
# Display the first few rows of the dataframe
print("Random Dataframe:")
print(head(random_df))
# Load required libraries
library(dplyr)
library(ggplot2)
library(caret)
library(plotly)
library(e1071)
# Set seed for reproducibility
set.seed(123)
# Generate a random dataframe
n <- 100
random_df <- data.frame(
X1 = rnorm(n),
X2 = rnorm(n),
X3 = rnorm(n)
)
# Add the Y column based on X1, X2, and X3
random_df$Y <- 2 * random_df$X1 - 3 * random_df$X2 + 0.5 * random_df$X3 + rnorm(n)
# Display the first few rows of the dataframe
print("Random Dataframe:")
print(head(random_df))
# Load required libraries
library(dplyr)
library(ggplot2)
library(caret)
library(plotly)
library(e1071)
# Set seed for reproducibility
set.seed(123)
# Generate a random dataframe
n <- 100
random_df <- data.frame(
X1 = rnorm(n),
X2 = rnorm(n),
X3 = rnorm(n)
)
# Add the Y column based on X1, X2, and X3
random_df$Y <- 2 * random_df$X1 - 3 * random_df$X2 + 0.5 * random_df$X3 + rnorm(n)
# Display the first few rows of the dataframe
print("Random Dataframe:")
print(head(random_df))
# Split the data into training and testing sets
trainIndex <- createDataPartition(random_df$Y, p = 0.8, list = FALSE)
train_data <- random_df[trainIndex, ]
test_data <- random_df[-trainIndex, ]
# Define the control parameters for caret
ctrl <- trainControl(method = "cv", number = 5)
# Train a Support Vector Machine (SVM) model
svm_model <- train(
Y ~ ., data = train_data,
method = "svm",
trControl = ctrl
)
# Load required libraries
library(dplyr)
library(ggplot2)
library(caret)
library(plotly)
library(e1071)
# Set seed for reproducibility
set.seed(123)
# Generate a random dataframe
n <- 100
random_df <- data.frame(
X1 = rnorm(n),
X2 = rnorm(n),
X3 = rnorm(n)
)
# Add the Y column based on X1, X2, and X3
random_df$Y <- 2 * random_df$X1 - 3 * random_df$X2 + 0.5 * random_df$X3 + rnorm(n)
# Display the first few rows of the dataframe
print("Random Dataframe:")
print(head(random_df))
# Split the data into training and testing sets
trainIndex <- createDataPartition(random_df$Y, p = 0.8, list = FALSE)
train_data <- random_df[trainIndex, ]
test_data <- random_df[-trainIndex, ]
# Define the control parameters for caret
ctrl <- trainControl(method = "cv", number = 5)
# Train a Support Vector Machine (SVM) model
svm_model <- train(
Y ~ ., data = train_data,
method = "svm",
trControl = ctrl
)
# Load required libraries
library(dplyr)
library(ggplot2)
library(caret)
library(plotly)
library(e1071)
# Set seed for reproducibility
set.seed(123)
# Generate a random dataframe
n <- 100
random_df <- data.frame(
X1 = rnorm(n),
X2 = rnorm(n),
X3 = rnorm(n)
)
# Add the Y column based on X1, X2, and X3
random_df$Y <- 2 * random_df$X1 - 3 * random_df$X2 + 0.5 * random_df$X3 + rnorm(n)
# Display the first few rows of the dataframe
print("Random Dataframe:")
print(head(random_df))
# Split the data into training and testing sets
trainIndex <- createDataPartition(random_df$Y, p = 0.8, list = FALSE)
train_data <- random_df[trainIndex, ]
test_data <- random_df[-trainIndex, ]
# Define the control parameters for caret
ctrl <- trainControl(method = "cv", number = 5)
# Train a Support Vector Machine (SVM) model
svm_model <- train(
Y ~ ., data = train_data,
method = "svm",
trControl = ctrl
)
# Split the data into training and testing sets
trainIndex <- createDataPartition(random_df$Y, p = 0.8, list = FALSE)
train_data <- random_df[trainIndex, ]
test_data <- random_df[-trainIndex, ]
# Train a Support Vector Machine (SVM) model
svm_model <- svm(Y ~ ., data = train_data)
# Make predictions on the test set
predictions <- predict(svm_model, newdata = test_data)
# Evaluate the model
accuracy <- mean(predictions == test_data$Y)
# Print the accuracy
print(paste("Accuracy:", round(accuracy, 4)))
# Visualize the results
plot_ly(x = test_data$Y, y = predictions, type = "scatter", mode = "markers") %>%
add_trace(x = c(min(test_data$Y), max(test_data$Y)), y = c(min(test_data$Y), max(test_data$Y)), mode = "lines", name = "Ideal Line") %>%
layout(title = "Actual vs. Predicted",
xaxis = list(title = "Actual"),
yaxis = list(title = "Predicted"))
# Split the data into training and testing sets
trainIndex <- createDataPartition(random_df$Y, p = 0.8, list = FALSE)
train_data <- random_df[trainIndex, ]
test_data <- random_df[-trainIndex, ]
# Train a Support Vector Machine (SVM) model
svm_model <- svm(Y ~ ., data = train_data)
# Make predictions on the test set
predictions <- predict(svm_model, newdata = test_data)
# Evaluate the model
conf_matrix <- table(Actual = test_data$Y, Predicted = predictions)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
# Print detailed accuracy metrics
print("Confusion Matrix:")
print(conf_matrix)
print(paste("Accuracy:", round(accuracy, 4)))
# Visualize the confusion matrix
plot_conf_matrix <- plot_ly(
x = rownames(conf_matrix),
y = colnames(conf_matrix),
z = as.matrix(conf_matrix),
type = "heatmap",
colorscale = "Viridis",
showscale = TRUE
) %>%
layout(title = "Confusion Matrix",
xaxis = list(title = "Predicted"),
yaxis = list(title = "Actual"))
# Visualize the results with a well-colored scatter plot
scatter_plot <- plot_ly(
data = test_data,
x = ~Y,
y = ~predictions,
type = "scatter",
mode = "markers",
marker = list(color = ~abs(Y - predictions), colorscale = "Viridis")
) %>%
add_trace(x = c(min(test_data$Y), max(test_data$Y)), y = c(min(test_data$Y), max(test_data$Y)), mode = "lines", name = "Ideal Line") %>%
layout(title = "Actual vs. Predicted",
xaxis = list(title = "Actual"),
yaxis = list(title = "Predicted"))
# Display the plots
subplot(plot_conf_matrix, scatter_plot)
# Split the data into training and testing sets
trainIndex <- createDataPartition(random_df$Y, p = 0.8, list = FALSE)
train_data <- random_df[trainIndex, ]
test_data <- random_df[-trainIndex, ]
# Train a Support Vector Machine (SVM) model
svm_model <- svm(Y ~ ., data = train_data)
# Make predictions on the test set
predictions <- predict(svm_model, newdata = test_data)
# Evaluate the model
conf_matrix <- table(Actual = test_data$Y, Predicted = predictions)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
# Print detailed accuracy metrics
print("Confusion Matrix:")
print(conf_matrix)
print(paste("Accuracy:", round(accuracy, 4)))
# Visualize the confusion matrix
plot_conf_matrix <- plot_ly(
x = rownames(conf_matrix),
y = colnames(conf_matrix),
z = as.matrix(conf_matrix),
type = "heatmap",
colorscale = "Viridis",
showscale = TRUE
) %>%
layout(title = "Confusion Matrix",
xaxis = list(title = "Predicted"),
yaxis = list(title = "Actual"))
# Visualize the results with a well-colored scatter plot
scatter_plot <- plot_ly(
data = test_data,
x = ~Y,
y = ~predictions,
type = "scatter",
mode = "markers",
marker = list(color = ~abs(Y - predictions), colorscale = "Viridis")
) %>%
add_trace(x = c(min(test_data$Y), max(test_data$Y)), y = c(min(test_data$Y), max(test_data$Y)), mode = "lines", name = "Ideal Line") %>%
layout(title = "Actual vs. Predicted",
xaxis = list(title = "Actual"),
yaxis = list(title = "Predicted"))
# Display the plots side by side
subplot(
list(plot_conf_matrix),
list(scatter_plot),
nrows = 1
)
# Split the data into training and testing sets
trainIndex <- createDataPartition(random_df$Y, p = 0.8, list = FALSE)
train_data <- random_df[trainIndex, ]
test_data <- random_df[-trainIndex, ]
# Train a Support Vector Machine (SVM) model
svm_model <- svm(Y ~ ., data = train_data)
# Make predictions on the test set
predictions <- predict(svm_model, newdata = test_data)
# Evaluate the model
accuracy <- mean(predictions == test_data$Y)
# Print the accuracy
print(paste("Accuracy:", round(accuracy, 4)))
# Visualize the results
plot_ly(x = test_data$Y, y = predictions, type = "scatter", mode = "markers") %>%
add_trace(x = c(min(test_data$Y), max(test_data$Y)), y = c(min(test_data$Y), max(test_data$Y)), mode = "lines", name = "Ideal Line") %>%
layout(title = "Actual vs. Predicted",
xaxis = list(title = "Actual"),
yaxis = list(title = "Predicted"))
# Split the data into training and testing sets
trainIndex <- createDataPartition(random_df$Y, p = 0.8, list = FALSE)
train_data <- random_df[trainIndex, ]
test_data <- random_df[-trainIndex, ]
# Train a Support Vector Machine (SVM) model
svm_model <- svm(Y ~ ., data = train_data)
# Make predictions on the test set
predictions <- predict(svm_model, newdata = test_data)
# Evaluate the model
conf_matrix <- table(Actual = test_data$Y, Predicted = predictions)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
# Print detailed accuracy metrics
print("Confusion Matrix:")
print(conf_matrix)
print(paste("Accuracy:", round(accuracy, 4)))
# Visualize the confusion matrix
plot_conf_matrix <- plot_ly(
x = rownames(conf_matrix),
y = colnames(conf_matrix),
z = as.matrix(conf_matrix),
type = "heatmap",
colorscale = "Viridis",
showscale = TRUE
) %>%
layout(title = "Confusion Matrix",
xaxis = list(title = "Predicted"),
yaxis = list(title = "Actual"))
# Print the confusion matrix plot
print(plot_conf_matrix)
# Visualize the results with a well-colored scatter plot
scatter_plot <- plot_ly(
data = test_data,
x = ~Y,
y = ~predictions,
type = "scatter",
mode = "markers",
marker = list(color = ~abs(Y - predictions), colorscale = "Viridis")
) %>%
add_trace(x = c(min(test_data$Y), max(test_data$Y)), y = c(min(test_data$Y), max(test_data$Y)), mode = "lines", name = "Ideal Line") %>%
layout(title = "Actual vs. Predicted",
xaxis = list(title = "Actual"),
yaxis = list(title = "Predicted"))
# Print the scatter plot
print(scatter_plot)
# Split the data into training and testing sets
trainIndex <- createDataPartition(random_df$Y, p = 0.8, list = FALSE)
train_data <- random_df[trainIndex, ]
test_data <- random_df[-trainIndex, ]
# Train a Support Vector Machine (SVM) model
svm_model <- svm(Y ~ ., data = train_data)
# Make predictions on the test set
predictions <- predict(svm_model, newdata = test_data)
# Evaluate the model
conf_matrix <- table(Actual = test_data$Y, Predicted = predictions)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
# Print detailed accuracy metrics
print("Confusion Matrix:")
print(conf_matrix)
print(paste("Accuracy:", round(accuracy, 4)))
# Visualize the confusion matrix
plot_conf_matrix <- plot_ly(
x = rownames(conf_matrix),
y = colnames(conf_matrix),
z = as.matrix(conf_matrix),
type = "heatmap",
colorscale = "Viridis",
showscale = TRUE
) %>%
layout(title = "Confusion Matrix",
xaxis = list(title = "Predicted"),
yaxis = list(title = "Actual"))
# Print the confusion matrix plot
print(plot_conf_matrix)
# Visualize the results with a well-colored scatter plot
scatter_plot <- plot_ly(
data = test_data,
x = ~Y,
y = ~predictions,
type = "scatter",
marker = list(color = ~abs(Y - predictions), colorscale = "Viridis")
) %>%
add_trace(x = c(min(test_data$Y), max(test_data$Y)), y = c(min(test_data$Y), max(test_data$Y)), mode = "lines", name = "Ideal Line") %>%
layout(title = "Actual vs. Predicted",
xaxis = list(title = "Actual"),
yaxis = list(title = "Predicted"))
# Print the scatter plot
print(scatter_plot)
# Split the data into training and testing sets
trainIndex <- createDataPartition(random_df$Y, p = 0.8, list = FALSE)
train_data <- random_df[trainIndex, ]
test_data <- random_df[-trainIndex, ]
# Train a Support Vector Machine (SVM) model
svm_model <- svm(Y ~ ., data = train_data)
# Make predictions on the test set
predictions <- predict(svm_model, newdata = test_data)
# Evaluate the model
conf_matrix <- table(Actual = test_data$Y, Predicted = predictions)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
# Print detailed accuracy metrics
print("Confusion Matrix:")
print(conf_matrix)
print(paste("Accuracy:", round(accuracy, 4)))
# Visualize the confusion matrix
plot_conf_matrix <- plot_ly(
x = rownames(conf_matrix),
y = colnames(conf_matrix),
z = as.matrix(conf_matrix),
type = "heatmap",
colorscale = "Viridis",
showscale = TRUE
) %>%
layout(title = "Confusion Matrix",
xaxis = list(title = "Predicted"),
yaxis = list(title = "Actual"))
# Print the confusion matrix plot
print(plot_conf_matrix)
# Split the data into training and testing sets
trainIndex <- createDataPartition(random_df$Y, p = 0.8, list = FALSE)
train_data <- random_df[trainIndex, ]
test_data <- random_df[-trainIndex, ]
# Train a Support Vector Machine (SVM) model
svm_model <- svm(Y ~ ., data = train_data)
# Make predictions on the test set
predictions <- predict(svm_model, newdata = test_data)
# Evaluate the model
conf_matrix <- table(Actual = test_data$Y, Predicted = predictions)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
# Print detailed accuracy metrics
print("Confusion Matrix:")
print(conf_matrix)
print(paste("Accuracy:", round(accuracy, 4)))
# Visualize the confusion matrix
plot_conf_matrix <- plot_ly(
x = rownames(conf_matrix),
y = colnames(conf_matrix),
z = as.matrix(conf_matrix),
type = "heatmap",
colorscale = "Viridis",
showscale = TRUE
) %>%
layout(title = "Confusion Matrix",
xaxis = list(title = "Predicted"),
yaxis = list(title = "Actual"))
# Print the confusion matrix plot
print(plot_conf_matrix)
# Load required libraries
library(dplyr)
library(ggplot2)
library(caret)
library(plotly)
# Set seed for reproducibility
set.seed(123)
# Generate a random dataframe
n <- 100
random_df <- data.frame(
X1 = rnorm(n),
X2 = rnorm(n),
X3 = rnorm(n)
)
# Add the Y column based on X1, X2, and X3
random_df$Y <- 2 * random_df$X1 - 3 * random_df$X2 + 0.5 * random_df$X3 + rnorm(n)
# Display the first few rows of the dataframe
print("Random Dataframe:")
print(head(random_df))
# Load required libraries
library(dplyr)
library(ggplot2)
library(caret)
library(plotly)
library(xgboost)
# Set seed for reproducibility
set.seed(123)
# Generate a random dataframe
n <- 100
random_df <- data.frame(
X1 = rnorm(n),
X2 = rnorm(n),
X3 = rnorm(n)
)
# Add the Y column based on X1, X2, and X3
random_df$Y <- 2 * random_df$X1 - 3 * random_df$X2 + 0.5 * random_df$X3 + rnorm(n)
# Display the first few rows of the dataframe
print("Random Dataframe:")
print(head(random_df))
# Set seed for reproducibility
set.seed(123)
# Split the data into training and testing sets
train_indices <- createDataPartition(random_df$Y, p = 0.8, list = FALSE)
train_data <- random_df[train_indices, ]
test_data <- random_df[-train_indices, ]
# Create an XGBoost model
xgb_model <- xgboost(data = as.matrix(train_data[, -4]), label = train_data$Y, nrounds = 100)
# Make predictions on the test set
predictions <- predict(xgb_model, as.matrix(test_data[, -4]))
# Evaluate model performance
accuracy <- sqrt(mean((predictions - test_data$Y)^2))
# Display the accuracy
print(paste("Model RMSE:", round(accuracy, 4)))
# Visualize actual vs. predicted values using plotly
plot_data <- data.frame(Actual = test_data$Y, Predicted = predictions)
plot <- plot_ly(plot_data, x = ~Actual, y = ~Predicted, type = 'scatter', mode = 'markers',
marker = list(color = 'blue', size = 8),
text = paste("Actual: ", test_data$Y, "<br>Predicted: ", round(predictions, 4)))
layout <- list(title = "Actual vs. Predicted Values",
xaxis = list(title = "Actual Values"),
yaxis = list(title = "Predicted Values"))
plot <- plot %>% layout(layout)
# Display the interactive plot
print(plot)
# Visualize actual vs. predicted values using plotly
plot_data <- data.frame(Actual = test_data$Y, Predicted = predictions)
plot <- plot_ly(plot_data, x = ~Actual, y = ~Predicted, type = 'scatter', mode = 'markers',
marker = list(color = 'blue', size = 8),
text = paste("Actual: ", test_data$Y, "<br>Predicted: ", round(predictions, 4)))
layout <- list(title = "Actual vs. Predicted Values",
xaxis = list(title = "Actual Values"),
yaxis = list(title = "Predicted Values"))
plot <- plot %>% layout(layout)
# Display the interactive plot
print(plot)
# Set seed for reproducibility
set.seed(123)
# Split the data into training and testing sets
train_indices <- createDataPartition(random_df$Y, p = 0.8, list = FALSE)
train_data <- random_df[train_indices, ]
test_data <- random_df[-train_indices, ]
# Create an XGBoost model
xgb_model <- xgboost(data = as.matrix(train_data[, -4]), label = train_data$Y, nrounds = 100)
# Make predictions on the test set
predictions <- predict(xgb_model, as.matrix(test_data[, -4]))
# Evaluate model performance
accuracy <- sqrt(mean((predictions - test_data$Y)^2))
# Display the accuracy
print(paste("Model RMSE:", round(accuracy, 4)))
